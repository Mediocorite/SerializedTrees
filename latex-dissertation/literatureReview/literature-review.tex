
\section{Literature Review}

% Things to consider when writing a good literature review.
% 1. Your goal is to define the research questions. Not to explain the solution.
% 2. High levels of independent thinking
% 3. Ability to critique obtained material
% 4. Ability to create clear and compelling research questions
% 5. Ability to identify key theories and concepts and these are articulated well.
% 6. There is a clear process of investigation with an explanation of key decisions. The findings are very well articulated.

% Do not be generic.

% Lay out your plan below.

% I want to talk about the functional programming paradigm with some examples, talk how the state and data being treated is a certain way about it. Expand on these concepts with data structures and then onto trees. Talk about generics programming and finally finish off with gibbon. 


\subsection{Functional Programming Paradigm}

The imperative coding paradigm relies on specific instructions and inputs to describe in detail the operations that transform data and state. It allows us the greatest control along with the greatest opportunity for errors, as the system is often not intelligent enough to prevent faulty algorithms and code. Attempts to strictly type and advance lispers help programmers, but fundamentally the method proves to be flexible but at the cost of forcing users to manage a lot of low-level features. Functional programming proves to be an attractive coding pattern, as it abstracts away to provide a declarative coding paradigm, where you chose to describe what the code does instead of how it does it. 

% Example for imperative code with strict typing


Functional programming relies on specific functions, i.e. given an input they will return an output. The functions themselves resemble mathematical notations, that describe what a state (often immutable data) changes into things. The lack of assignment statement causes the very variable to be immutable, and thus doesn't have any sidee The compiler proceeds to perform the low-level logic of actual memory manipulation, removing an avenue for errors and performance optimization.
% Add an example of the functional code

Functional programming excels when working closely with data and large magnitude of computation. It's safer approach and more concise nature allows programmers to create reliable software. In Trends in Functional Programming 13\textsuperscript{th} International Symposium (\textcite{turner2004total}), is a great breakdown of how functional programming is used in various sections of the industry, revolutionizing and setting a standard in many cases.

Functional programming began with LISP language in the very essence, developed by John McCarthy in 1960 (\textcite{mccarthy1960lisp}), where McCarthy aimed to create a language that would work with symbolic data. What began as the basis, quickly expanded into multiple concepts that describe a modern functional programming language:

\begin{itemize}
  \item The Lambda Calculus (\textcite{Rosser1941-ROSCAT-17}) depicted typeless theory and theorems that are rudimentary building blocks of FP, describing how the functions interact to create a programming logic. It was further explored as the formation of Algol 60 (\textcite{backus1963revised}).
  \item Development of lazy evaluation, contributed to SASL and polymorphism attributed in development to ISWIM. Various evolution in the field happened in Edinburgh throughout the late 1960s and 1980s.
  \item General development of more popular languages such as Miranda and Haskell that brings the current state of FP to be lazily evaluated, typed with algebraic types with polymorphism, have functions that are high order and have features such as pattern matching inbuilt. 
\end{itemize}

% This section should only talk about FP in terms of data
% FP proves to be useful in various applications, a perception that is established by its various applications in multiple domains.
% \begin{itemize}
%   \item Use of reversible computations with the help of monad that helps in concepts such as helping the compiler to resume parsing if an error happens or rollback to a more stable state of the application (\textcite{jaskelioff2015functional})
%   \item Use of FP in cloud computing technologies and supercomputers (\textcite{kasyanov2018system})
%   \item It's an application in distributed computing, concurrency control and fault tolerance (\textcite{burton1987functional})
%   \item Implementation of FP in web framework like Ocsigen (\textcite{balat2009experience})
% \end{itemize}
%

The two concepts that dictate most of the success of functional programming in various industries are depicted in the paper Why Functional Programming Matters. (\textcite{hughes1989functional})
\begin{enumerate}
  \item The concept of modularity: 
        A great aspect of Functional language is the level of abstraction associated. As we strictly describe what needs to be done, and rely on the compiler to create the low-level logic instead, our final code ends up being a collage of reusable functions. These can be reused to expand the functionality and are modular enough that changes to one of these components should not break the entire code base. As most languages deal with immutable data structures and lack of side effects, it's relatively easier to diagnose a solve an issue in an isolated manner and lets us enforce separations of concerns effectively.
  \item The concise nature of FP:
        The code generally is much more concise than its imperative counterpart. Most code consists of a description of functions, data structures, and an immutable declaration of variables. A large portion of often reused code or boilerplate that is associated with imperative programming is discarded to achieve the maximum resemblance to pure mathematical notions, that inspired functional programming's origin. 
\end{enumerate}

\subsection{Data Structures in Functional Programming}
\subsection{Trees in Functional Programming}
\subsection{Generics in Functional Programming & Improving Trees}

We have discussed several advantages of the FP in the previous section. However, there are still improvements that need to be made. Popular languages such as Haskell and Idris use heap memory when defining objects such as a tree. One improvement that a programmer can make is to change the data representation to accommodate more specific data allocation and modeling, thus forgoing the need of the heap memory. This process is called packing, where a programmer manually repacks a complicated structure such as a tree into a byte array for much faster traversal (\textcite{goldfarb2013general}) and smaller footprint (\textcite{makino1990vectorization}) (\textcite{meyerovich2011data}). This process is manual and needs to specified by the programmer separately. 

There are new ideas when it comes to storing the traversing trees which haven't been explored in the function programming space. Implementation of suppression of tree structure in an continuous stream of data as observed in Compressed Suffix Trees with Full Functionality (\textcite{sadakane2007compressed} ). This provides a great direction on how we can achieve improvements in storage and processing of trees, with the notion of arranging the pieces of trees in a certain order, improving it's overall size and speed. This arrangement also has extensive research, with notable techniques being Fractal prefetching B+-trees: Optimizing both cache and disk performance (\textcite{chen2002fractal}), Bonsai: High-performance adaptive merge tree sorting (\textcite{samardzic2020bonsai}) and Lb+ trees: optimizing persistent index performance on 3dxpoint memory (\textcite{liu2020lb+})

In the realm of functional programming, the most notable is the work of Michael Vollmer and team in Compiling Tree Transforms to Operate on Packed
Representations (\textcite{vollmer2017compiling}) where they discuss a method of creating packed representations of tree at a compiler level. Since LISP, the notion of implementing the functionality trees and their reliance of heap memory allocation hadn't been changed. The team proposed a method to create the tree using a packed byte array access, where the tree will be arranged in preorder.  To solve the issue of traversal, they also add a few pointers that describe where the next node of the branch lies within the array, thus allowing random access traversal. This, however, introduced some performance bottleneck, as pointers explain no information in itself that is useful, as well as they introduce ambiguity when judging its memory use (\textcite{bagnara2023c}). 

From the research, the team created Gibbon compiler, built on Racket to convert Haskell code to be converted into preordered byte arrays. The notion was further explored by the same team in LoCal: A Language for Programs Operating on Serialized Data \textcite{vollmer2019local}, where the team developed and intermediate language to operate in between the compiler and the code, allowing user to perform better calculus focus data manipulation for better performance. 

The work on Gibbon is very impressive, but it does have few caveats. Mainly, it performs most of its function with the idea of storing the tree on a buffer in C. In terms of requirements, the concepts can also be implemented naively in a language, by employing its primitives. Research on such an implementation, whether its more unfriendly or perhaps implementation of different tree traversal techniques is lacking. 

\subsection{Conclusion}
FP proves to be very impact programming paradigm with myriads of use cases and applications. The idea of improving its performance when dealing with trees has been explored in details by Vollmer and team, however, as of its current state, it relies on a external library with different language to address this concern. A need for attempting the methods of the compiler within the languages exists as it may prove to be more user friendly and perhaps even outperform the existing methods. Research on finding better methods of implementing also remains a tasks and thus formulates our research questions.